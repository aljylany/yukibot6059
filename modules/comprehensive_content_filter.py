"""
Ù†Ø¸Ø§Ù… ÙƒØ´Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø´Ø§Ù…Ù„ ÙˆØ§Ù„Ù…ØªÙ‚Ø¯Ù…
Comprehensive Content Detection and Moderation System
"""

import logging
import asyncio
import io
import json
import sqlite3
import base64
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from enum import Enum

try:
    from PIL import Image
except ImportError:
    Image = None

try:
    import google.generativeai as genai
except ImportError:
    genai = None

try:
    import cv2
    import numpy as np
except ImportError:
    cv2 = None
    np = None

from aiogram.types import Message, PhotoSize, Document, Video, Animation, Sticker, ChatPermissions
from aiogram.exceptions import TelegramBadRequest

class ViolationType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª"""
    TEXT_PROFANITY = "text_profanity"          # Ø³Ø¨Ø§Ø¨ Ù†ØµÙŠ
    SEXUAL_CONTENT = "sexual_content"          # Ù…Ø­ØªÙˆÙ‰ Ø¬Ù†Ø³ÙŠ
    ADULT_IMAGE = "adult_image"                # ØµÙˆØ± Ø¥Ø¨Ø§Ø­ÙŠØ©
    VIOLENT_CONTENT = "violent_content"        # Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†ÙŠÙ
    HATE_SPEECH = "hate_speech"                # Ø®Ø·Ø§Ø¨ ÙƒØ±Ø§Ù‡ÙŠØ©
    INAPPROPRIATE_STICKER = "inappropriate_sticker"  # Ù…Ù„ØµÙ‚ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨
    SUSPICIOUS_FILE = "suspicious_file"        # Ù…Ù„Ù Ù…Ø´Ø¨ÙˆÙ‡

class SeverityLevel(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø®Ø·ÙˆØ±Ø©"""
    LOW = 1      # Ø®ÙÙŠÙ - ØªØ­Ø°ÙŠØ±
    MEDIUM = 2   # Ù…ØªÙˆØ³Ø· - ÙƒØªÙ… Ù…Ø¤Ù‚Øª
    HIGH = 3     # Ø¹Ø§Ù„ÙŠ - ÙƒØªÙ… Ø·ÙˆÙŠÙ„
    SEVERE = 4   # Ø´Ø¯ÙŠØ¯ - ÙƒØªÙ… Ø¯Ø§Ø¦Ù…
    EXTREME = 5  # Ù…ØªØ·Ø±Ù - Ø·Ø±Ø¯ Ù†Ù‡Ø§Ø¦ÙŠ

class PunishmentAction(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª"""
    WARNING = "warning"              # ØªØ­Ø°ÙŠØ± ÙÙ‚Ø·
    MUTE_5MIN = "mute_5min"         # ÙƒØªÙ… 5 Ø¯Ù‚Ø§Ø¦Ù‚
    MUTE_30MIN = "mute_30min"       # ÙƒØªÙ… 30 Ø¯Ù‚ÙŠÙ‚Ø©
    MUTE_1HOUR = "mute_1hour"       # ÙƒØªÙ… Ø³Ø§Ø¹Ø©
    MUTE_6HOUR = "mute_6hour"       # ÙƒØªÙ… 6 Ø³Ø§Ø¹Ø§Øª
    MUTE_24HOUR = "mute_24hour"     # ÙƒØªÙ… 24 Ø³Ø§Ø¹Ø©
    MUTE_PERMANENT = "mute_permanent"  # ÙƒØªÙ… Ø¯Ø§Ø¦Ù…
    BAN_TEMPORARY = "ban_temporary"    # Ø­Ø¸Ø± Ù…Ø¤Ù‚Øª
    BAN_PERMANENT = "ban_permanent"    # Ø·Ø±Ø¯ Ù†Ù‡Ø§Ø¦ÙŠ

class ComprehensiveContentFilter:
    """Ù†Ø¸Ø§Ù… ÙƒØ´Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø´Ø§Ù…Ù„ ÙˆØ§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        self.enabled = False  # ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
        self.api_keys = []
        self.current_key_index = 0
        self.model = None
        self._load_api_keys()
        self._setup_model()
        self._init_punishment_system()
        
        # Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¬Ù†Ø³ÙŠ Ù„Ù„Ù†ØµÙˆØµ
        self.sexual_context_keywords = [
            # ÙƒÙ„Ù…Ø§Øª Ø¬Ù†Ø³ÙŠØ© ØµØ±ÙŠØ­Ø©
            "Ø¬Ù†Ø³", "Ø¬Ù…Ø§Ø¹", "Ù…Ø¬Ø§Ù…Ø¹Ù‡", "Ù†ÙƒØ§Ø­", "Ù…Ù†Ø§ÙƒÙ‡", "Ø³ÙƒØ³", "Ù…Ù…Ø§Ø±Ø³Ù‡",
            "Ù…Ø¹Ø§Ø´Ø±Ù‡", "Ù„ÙˆØ§Ø·", "Ù„ÙˆØ·ÙŠ", "Ù„ÙˆØ·ÙŠÙ‡", "Ø´Ø§Ø°", "Ù…Ø«Ù„ÙŠ", "Ù…Ø«Ù„ÙŠÙ‡",
            
            # Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø¬Ø³Ù… Ø§Ù„Ø­Ø³Ø§Ø³Ø©
            "ØµØ¯Ø±", "Ø«Ø¯ÙŠ", "Ù…Ø¤Ø®Ø±Ø©", "Ø£Ø±Ø¯Ø§Ù", "ÙØ®Ø°", "Ø³Ø§Ù‚", "Ø¨Ø·Ù†",
            
            # Ø£ÙØ¹Ø§Ù„ Ø¬Ù†Ø³ÙŠØ©
            "Ø¹Ø§Ù†Ù‚", "Ù‚Ø¨Ù„", "Ù„Ù…Ø³", "Ø§Ø­ØªØ¶Ù†", "Ø¯Ø§Ø¹Ø¨", "ØªÙ„Ø§Ù…Ø³",
            
            # ÙƒÙ„Ù…Ø§Øª Ø¥ÙŠØ­Ø§Ø¦ÙŠØ©
            "Ø´Ù‡ÙˆØ©", "Ø±ØºØ¨Ø©", "Ø¥Ø«Ø§Ø±Ø©", "Ù…ØªØ¹Ø©", "Ù„Ø°Ø©", "Ø§Ø´ØªÙ‡Ø§Ø¡",
            
            # Ù…ØµØ·Ù„Ø­Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            "sex", "porn", "nude", "naked", "adult", "xxx", "kiss", "touch", "sexy"
        ]
        
        # Ø£Ù†Ù…Ø§Ø· Ù…Ù„ØµÙ‚Ø§Øª Ù…Ø´Ø¨ÙˆÙ‡Ø©
        self.suspicious_sticker_patterns = [
            # Ù…Ù„ØµÙ‚Ø§Øª Ø¬Ù†Ø³ÙŠØ©
            "sex", "porn", "nude", "naked", "adult", "xxx",
            "Ø¥Ø¨Ø§Ø­ÙŠ", "Ø¬Ù†Ø³", "Ø¹Ø§Ø±ÙŠ", "Ø¹Ø§Ø±ÙŠØ©", "Ø´Ù‡ÙˆØ©",
            
            # Ù…Ù„ØµÙ‚Ø§Øª Ø¹Ù†ÙŠÙØ©
            "violence", "blood", "kill", "death", "gun", "knife",
            "Ø¹Ù†Ù", "Ø¯Ù…", "Ù‚ØªÙ„", "Ù…ÙˆØª", "Ø³Ù„Ø§Ø­", "Ø³ÙƒÙŠÙ†",
            
            # Ù…Ù„ØµÙ‚Ø§Øª ÙƒØ±Ø§Ù‡ÙŠØ©
            "hate", "nazi", "terror", "racist",
            "ÙƒØ±Ø§Ù‡ÙŠØ©", "Ø¹Ù†ØµØ±ÙŠØ©", "Ø¥Ø±Ù‡Ø§Ø¨"
        ]

    def _load_api_keys(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ API"""
        try:
            with open('api.txt', 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            for line in lines:
                line = line.strip()
                if line.startswith('AIza'):
                    self.api_keys.append(line)
            
            if self.api_keys:
                logging.info(f"ğŸ”‘ ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.api_keys)} Ù…ÙØ§ØªÙŠØ­ Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„")
            else:
                logging.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ AI Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„")
                self.enabled = False
                
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ API: {e}")
            self.enabled = False

    def _setup_model(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        if not self.api_keys or not genai:
            self.enabled = False
            return
        
        try:
            api_key = self.api_keys[self.current_key_index]
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            logging.info("ğŸ§  ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {e}")
            self.enabled = False

    def _init_punishment_system(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø§Ù„Ù…ØªØ¯Ø±Ø¬"""
        try:
            conn = sqlite3.connect('comprehensive_filter.db')
            cursor = conn.cursor()
            
            # Ø¬Ø¯ÙˆÙ„ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ø´Ø§Ù…Ù„
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS violation_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER NOT NULL,
                chat_id INTEGER NOT NULL,
                violation_type TEXT NOT NULL,
                severity_level INTEGER NOT NULL,
                content_summary TEXT,
                punishment_applied TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                expires_at TIMESTAMP
            )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS group_filter_settings (
                chat_id INTEGER PRIMARY KEY,
                text_filter_enabled BOOLEAN DEFAULT TRUE,
                media_filter_enabled BOOLEAN DEFAULT TRUE,
                sticker_filter_enabled BOOLEAN DEFAULT TRUE,
                auto_punishment_enabled BOOLEAN DEFAULT TRUE,
                admin_reports_enabled BOOLEAN DEFAULT TRUE,
                severity_threshold INTEGER DEFAULT 2,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ†
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS admin_reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                chat_id INTEGER NOT NULL,
                user_id INTEGER NOT NULL,
                admin_id INTEGER,
                violation_type TEXT NOT NULL,
                severity_level INTEGER NOT NULL,
                content_summary TEXT,
                action_taken TEXT,
                report_status TEXT DEFAULT 'pending',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                resolved_at TIMESTAMP
            )
            ''')
            
            # Ø¬Ø¯ÙˆÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ©
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_violation_points (
                user_id INTEGER,
                chat_id INTEGER,
                total_points INTEGER DEFAULT 0,
                last_violation TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                punishment_level INTEGER DEFAULT 0,
                is_permanently_banned BOOLEAN DEFAULT FALSE,
                PRIMARY KEY (user_id, chat_id)
            )
            ''')
            
            conn.commit()
            conn.close()
            
            logging.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„")
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª: {e}")

    async def comprehensive_content_check(self, message: Message) -> Dict[str, Any]:
        """
        Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        """
        results = {
            'has_violations': False,
            'violations': [],
            'total_severity': 0,
            'recommended_action': PunishmentAction.WARNING,
            'admin_notification_required': False
        }
        
        try:
            # ÙØ­Øµ Ø§Ù„Ù†Øµ
            if message.text:
                logging.info(f"ğŸ” ÙØ­Øµ Ø§Ù„Ù†Øµ: '{message.text[:30]}{'...' if len(message.text) > 30 else ''}'")
                text_result = await self._check_text_content(message.text)
                if text_result['has_violation']:
                    logging.warning(f"âš ï¸ Ù…Ø®Ø§Ù„ÙØ© Ù†ØµÙŠØ©: {text_result['violation_type']} (Ø®Ø·ÙˆØ±Ø©: {text_result['severity']})")
                    results['violations'].append(text_result)
                    results['total_severity'] += text_result['severity']
                else:
                    logging.info("âœ… Ø§Ù„Ù†Øµ Ù†Ø¸ÙŠÙ")
            
            # ÙØ­Øµ Ø§Ù„ØµÙˆØ±
            if message.photo:
                logging.info("ğŸ” ÙØ­Øµ Ø§Ù„ØµÙˆØ±Ø©...")
                image_result = await self._check_image_content(message)
                if image_result['has_violation']:
                    logging.warning(f"âš ï¸ Ù…Ø®Ø§Ù„ÙØ© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©: {image_result['violation_type']} (Ø®Ø·ÙˆØ±Ø©: {image_result['severity']})")
                    results['violations'].append(image_result)
                    results['total_severity'] += image_result['severity']
                else:
                    logging.info("âœ… Ø§Ù„ØµÙˆØ±Ø© Ù†Ø¸ÙŠÙØ©")
            
            # ÙØ­Øµ Ø§Ù„Ù…Ù„ØµÙ‚Ø§Øª
            if message.sticker:
                logging.info(f"ğŸ” ÙØ­Øµ Ø§Ù„Ù…Ù„ØµÙ‚: {message.sticker.emoji or 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}")
                sticker_result = await self._check_sticker_content(message)
                if sticker_result['has_violation']:
                    logging.warning(f"âš ï¸ Ù…Ø®Ø§Ù„ÙØ© ÙÙŠ Ø§Ù„Ù…Ù„ØµÙ‚: {sticker_result['violation_type']} (Ø®Ø·ÙˆØ±Ø©: {sticker_result['severity']})")
                    results['violations'].append(sticker_result)
                    results['total_severity'] += sticker_result['severity']
                else:
                    logging.info("âœ… Ø§Ù„Ù…Ù„ØµÙ‚ Ù†Ø¸ÙŠÙ")
            
            # ÙØ­Øµ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
            if message.video:
                logging.info("ğŸ” ÙØ­Øµ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ...")
                video_result = await self._check_video_content(message)
                if video_result['has_violation']:
                    logging.warning(f"âš ï¸ Ù…Ø®Ø§Ù„ÙØ© ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {video_result['violation_type']} (Ø®Ø·ÙˆØ±Ø©: {video_result['severity']})")
                    results['violations'].append(video_result)
                    results['total_severity'] += video_result['severity']
                else:
                    logging.info("âœ… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù†Ø¸ÙŠÙ")
            
            # ÙØ­Øµ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©
            if message.animation:
                logging.info("ğŸ” ÙØ­Øµ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ù…ØªØ­Ø±Ùƒ...")
                animation_result = await self._check_animation_content(message)
                if animation_result['has_violation']:
                    logging.warning(f"âš ï¸ Ù…Ø®Ø§Ù„ÙØ© ÙÙŠ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ù…ØªØ­Ø±Ùƒ: {animation_result['violation_type']} (Ø®Ø·ÙˆØ±Ø©: {animation_result['severity']})")
                    results['violations'].append(animation_result)
                    results['total_severity'] += animation_result['severity']
                else:
                    logging.info("âœ… Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù†Ø¸ÙŠÙ")
            
            # ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª
            if message.document:
                logging.info(f"ğŸ” ÙØ­Øµ Ø§Ù„Ù…Ù„Ù: {message.document.file_name or 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}")
                document_result = await self._check_document_content(message)
                if document_result['has_violation']:
                    logging.warning(f"âš ï¸ Ù…Ø®Ø§Ù„ÙØ© ÙÙŠ Ø§Ù„Ù…Ù„Ù: {document_result['violation_type']} (Ø®Ø·ÙˆØ±Ø©: {document_result['severity']})")
                    results['violations'].append(document_result)
                    results['total_severity'] += document_result['severity']
                else:
                    logging.info("âœ… Ø§Ù„Ù…Ù„Ù Ù†Ø¸ÙŠÙ")
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            if results['violations']:
                results['has_violations'] = True
                results['recommended_action'] = self._determine_punishment_action(
                    results['total_severity'], 
                    message.from_user.id, 
                    message.chat.id
                )
                
                # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØªØ·Ù„Ø¨ Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ†
                results['admin_notification_required'] = (
                    results['total_severity'] >= SeverityLevel.HIGH.value or
                    any(v['violation_type'] in [
                        ViolationType.ADULT_IMAGE.value,
                        ViolationType.VIOLENT_CONTENT.value,
                        ViolationType.HATE_SPEECH.value
                    ] for v in results['violations'])
                )
            
            return results
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„: {e}")
            return results

    async def _check_text_content(self, text: str) -> Dict[str, Any]:
        """ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†ØµÙŠ Ù„Ù„Ø³Ø¨Ø§Ø¨ ÙˆØ§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¬Ù†Ø³ÙŠ"""
        result = {
            'has_violation': False,
            'violation_type': None,
            'severity': 0,
            'details': {},
            'content_summary': text[:100] + "..." if len(text) > 100 else text
        }
        
        try:
            text_lower = text.lower()
            
            # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¢Ù…Ù†Ø© - Ù„Ø§ ÙŠØ¬Ø¨ Ø§Ø¹ØªØ¨Ø§Ø±Ù‡Ø§ Ø³Ø¨Ø§Ø¨ Ø£Ø¨Ø¯Ø§Ù‹
            safe_words = [
                "Ø¨ÙˆØª", "bot", "Ø±ÙˆØ¨ÙˆØª", "ÙŠÙˆÙƒÙŠ", "yuki", "Ø¢Ù„ÙŠ", "Ø°ÙƒÙŠ", "Ù…Ø³Ø§Ø¹Ø¯", "Ø¨Ø±Ù†Ø§Ù…Ø¬",
                "ØªØ·Ø¨ÙŠÙ‚", "Ø³ÙŠØ±ÙŠ", "siri", "Ø£Ù„ÙŠÙƒØ³Ø§", "alexa", "Ø¬ÙˆØ¬Ù„", "google", "Ù…Ø§Ø³Ù†Ø¬Ø±", "messenger",
                "ÙˆØ§ØªØ³Ø§Ø¨", "whatsapp", "ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…", "telegram", "Ø¯ÙŠØ³ÙƒÙˆØ±Ø¯", "discord", 
                "ØºØ¨ÙŠ", "Ù…Ø¬Ù†ÙˆÙ†", "Ø³ÙŠØ¡", "Ø¬ÙŠØ¯", "Ø¹Ø§Ø¯ÙŠ", "Ø·Ø¨ÙŠØ¹ÙŠ", "Ù…ÙÙŠØ¯", "Ø±Ø§Ø¦Ø¹", "Ø¬Ù…ÙŠÙ„", "Ø­Ù„Ùˆ",
                "Ø´ÙƒØ±Ø§", "Ø´ÙƒØ±Ø§Ù‹", "thanks", "Ù…Ø±Ø­Ø¨Ø§", "Ù…Ø±Ø­Ø¨Ø§Ù‹", "hello", "hi", "Ø£Ù‡Ù„Ø§", "Ø£Ù‡Ù„Ø§Ù‹",
                "Ù†Ø¹Ù…", "Ù„Ø§", "yes", "no", "Ø±Ø¨Ù…Ø§", "maybe", "perhaps", "Ù„Ù…Ø§Ø°Ø§", "why", "ÙƒÙŠÙ", "how",
                "Ù…ØªÙ‰", "when", "Ø£ÙŠÙ†", "where", "Ù…Ø§Ø°Ø§", "what", "Ù…Ù†", "who", "ÙƒÙ…", "how much"
            ]
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¢Ù…Ù†Ø© Ø£ÙˆÙ„Ø§Ù‹
            words_in_text = text_lower.split()
            is_safe_text = any(safe_word in text_lower for safe_word in safe_words)
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¢Ù…Ù†Ø© ÙÙ‚Ø·ØŒ Ù„Ø§ Ù†ÙØ­ØµÙ‡ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
            if is_safe_text and len(text_lower.strip()) <= 50:
                logging.info(f"âœ… ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¢Ù…Ù†: '{text[:30]}...'")
                return result
            
            # ÙØ­Øµ Ù…ØªÙ‚Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Gemini (ÙÙ‚Ø· Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©)
            if self.model and len(text_lower.strip()) > 5:  # Ù†ÙØ­Øµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© ÙÙ‚Ø·
                # ØªØ­Ù‚Ù‚ Ø¥Ø¶Ø§ÙÙŠ - Ù„Ø§ Ù†ÙØ­Øµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¢Ù…Ù†Ø© ÙÙ‚Ø·
                if not is_safe_text:
                    ai_result = await self._check_text_with_ai(text)
                    if ai_result.get('has_profanity', False):
                        # ØªÙ‚Ù„ÙŠÙ„ Ø´Ø¯Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
                        severity = ai_result.get('severity', SeverityLevel.MEDIUM.value)
                        if severity > SeverityLevel.MEDIUM.value:
                            severity = SeverityLevel.MEDIUM.value  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø´Ø¯Ø©
                        
                        result['has_violation'] = True
                        result['violation_type'] = ViolationType.TEXT_PROFANITY.value
                        result['severity'] = severity
                        result['details'] = {
                            'ai_analysis': ai_result.get('reason', 'Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨'),
                            'confidence': ai_result.get('confidence', 0),
                            'method': 'ai_gemini_filtered'
                        }
                        return result
            
            # ÙØ­Øµ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¬Ù†Ø³ÙŠ
            sexual_matches = []
            for keyword in self.sexual_context_keywords:
                if keyword in text_lower:
                    sexual_matches.append(keyword)
            
            if sexual_matches:
                result['has_violation'] = True
                result['violation_type'] = ViolationType.SEXUAL_CONTENT.value
                result['severity'] = SeverityLevel.MEDIUM.value
                result['details'] = {
                    'matched_keywords': sexual_matches[:3],
                    'context': 'sexual_content_detected'
                }
                return result
            
            # ÙØ­Øµ Ø§Ù„Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ Ø§Ù„Ø®Ø·ÙŠØ± ÙÙ‚Ø· (Ø§Ø­ØªÙŠØ§Ø·ÙŠ)
            severe_banned_words = [
                "Ø´Ø±Ù…ÙˆØ·", "Ø¹Ø§Ù‡Ø±Ø©", "Ù…Ù†ÙŠÙƒ", "Ù†ÙŠÙƒ", "ÙƒØ³", "Ø²Ø¨", "Ø·ÙŠØ²", "Ø®Ø±Ø§",
                "Ù…Ù†ÙŠÙˆÙƒ", "Ø§ÙŠØ±ÙŠ", "Ø§Ù†ÙŠÙƒ", "Ø¹Ø±Øµ", "Ù‚Ø­Ø¨Ø©", "ÙƒØ³Ù…Ùƒ", "Ù‚Ø§ÙˆÙˆØ¯", "Ø²ÙˆÙ…Ù„"
            ]
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³Ø¨Ø§Ø¨
            # ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„ "Ø­Ù…Ø§Ø±"ØŒ "Ø§Ø­Ù…Ù‚"ØŒ "ØºØ¨ÙŠ" Ù„Ù… ØªØ¹Ø¯ ØªÙØ¹ØªØ¨Ø± Ø³Ø¨Ø§Ø¨ Ø®Ø·ÙŠØ±
            
            for banned_word in severe_banned_words:
                if banned_word in text_lower:
                    result['has_violation'] = True
                    result['violation_type'] = ViolationType.TEXT_PROFANITY.value
                    result['severity'] = SeverityLevel.HIGH.value
                    result['details'] = {
                        'matched_word': banned_word,
                        'method': 'database_fallback'
                    }
                    return result
            
            return result
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ù†Øµ: {e}")
            return result

    async def _check_image_content(self, message: Message) -> Dict[str, Any]:
        """ÙØ­Øµ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙˆØ±"""
        result = {
            'has_violation': False,
            'violation_type': None,
            'severity': 0,
            'details': {},
            'content_summary': f"ØµÙˆØ±Ø© Ù…Ù† {message.from_user.first_name}"
        }
        
        try:
            if not self.model or not message.photo:
                return result
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
            photo = message.photo[-1]  # Ø£ÙƒØ¨Ø± Ø­Ø¬Ù…
            file_info = await message.bot.get_file(photo.file_id)
            
            if not file_info.file_path:
                return result
            
            file_data = await message.bot.download_file(file_info.file_path)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
            analysis_result = await self._analyze_image_with_ai(file_data.read())
            
            if analysis_result.get('is_inappropriate', False):
                result['has_violation'] = True
                
                # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ©
                category = analysis_result.get('category', 'unknown')
                if category == 'adult':
                    result['violation_type'] = ViolationType.ADULT_IMAGE.value
                    result['severity'] = SeverityLevel.SEVERE.value
                elif category == 'violence':
                    result['violation_type'] = ViolationType.VIOLENT_CONTENT.value
                    result['severity'] = SeverityLevel.HIGH.value
                elif category == 'hate':
                    result['violation_type'] = ViolationType.HATE_SPEECH.value
                    result['severity'] = SeverityLevel.HIGH.value
                else:
                    result['violation_type'] = ViolationType.ADULT_IMAGE.value
                    result['severity'] = SeverityLevel.MEDIUM.value
                
                result['details'] = {
                    'ai_confidence': analysis_result.get('confidence', 0),
                    'ai_reason': analysis_result.get('reason', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
                    'category': category
                }
            
            return result
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return result

    async def _check_sticker_content(self, message: Message) -> Dict[str, Any]:
        """ÙØ­Øµ Ø§Ù„Ù…Ù„ØµÙ‚Ø§Øª"""
        result = {
            'has_violation': False,
            'violation_type': None,
            'severity': 0,
            'details': {},
            'content_summary': f"Ù…Ù„ØµÙ‚: {message.sticker.emoji or 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}"
        }
        
        try:
            sticker = message.sticker
            
            # ÙØ­Øµ emoji Ø§Ù„Ù…Ù„ØµÙ‚
            if sticker.emoji:
                suspicious_emojis = ['ğŸ†', 'ğŸ‘', 'ğŸ’¦', 'ğŸ”', 'ğŸ˜ˆ', 'ğŸ’‹', 'ğŸ‘…']
                if sticker.emoji in suspicious_emojis:
                    result['has_violation'] = True
                    result['violation_type'] = ViolationType.INAPPROPRIATE_STICKER.value
                    result['severity'] = SeverityLevel.LOW.value
                    result['details'] = {'reason': 'suspicious_emoji', 'emoji': sticker.emoji}
                    return result
            
            # ÙØ­Øµ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            file_name = getattr(sticker, 'file_name', '') or ''
            file_name_lower = file_name.lower()
            
            for pattern in self.suspicious_sticker_patterns:
                if pattern in file_name_lower:
                    result['has_violation'] = True
                    result['violation_type'] = ViolationType.INAPPROPRIATE_STICKER.value
                    result['severity'] = SeverityLevel.MEDIUM.value
                    result['details'] = {
                        'reason': 'suspicious_filename',
                        'matched_pattern': pattern,
                        'filename': file_name
                    }
                    return result
            
            # ÙØ­Øµ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„ØµÙ‚ ÙƒØµÙˆØ±Ø© (Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†)
            if sticker.is_static:
                try:
                    file_info = await message.bot.get_file(sticker.file_id)
                    if file_info.file_path:
                        file_data = await message.bot.download_file(file_info.file_path)
                        
                        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© ÙˆÙØ­ØµÙ‡Ø§
                        if Image:
                            image = Image.open(io.BytesIO(file_data.read()))
                            # ØªØ­ÙˆÙŠÙ„ WEBP Ø¥Ù„Ù‰ PNG
                            png_bytes = io.BytesIO()
                            image.save(png_bytes, format='PNG')
                            png_bytes.seek(0)
                            
                            analysis_result = await self._analyze_image_with_ai(png_bytes.read())
                            
                            if analysis_result.get('is_inappropriate', False):
                                result['has_violation'] = True
                                result['violation_type'] = ViolationType.INAPPROPRIATE_STICKER.value
                                result['severity'] = SeverityLevel.HIGH.value
                                result['details'] = {
                                    'reason': 'ai_analysis',
                                    'ai_confidence': analysis_result.get('confidence', 0),
                                    'ai_category': analysis_result.get('category', 'unknown')
                                }
                                return result
                                
                except Exception as sticker_analysis_error:
                    logging.debug(f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ØµÙ‚: {sticker_analysis_error}")
            
            return result
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù„ØµÙ‚: {e}")
            return result

    async def _check_video_content(self, message: Message) -> Dict[str, Any]:
        """ÙØ­Øµ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
        result = {
            'has_violation': False,
            'violation_type': None,
            'severity': 0,
            'details': {},
            'content_summary': f"ÙÙŠØ¯ÙŠÙˆ Ù…Ù† {message.from_user.first_name}"
        }
        
        try:
            video = message.video
            
            # ÙØ­Øµ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            file_name = getattr(video, 'file_name', '') or ''
            file_name_lower = file_name.lower()
            
            suspicious_words = [
                'sex', 'porn', 'adult', 'xxx', 'nude', 'naked',
                'Ø¥Ø¨Ø§Ø­ÙŠ', 'Ø¬Ù†Ø³', 'Ø¹Ø§Ø±ÙŠ', 'Ø¹Ø§Ø±ÙŠØ©', 'ÙØ§Ø¶Ø­'
            ]
            
            for word in suspicious_words:
                if word in file_name_lower:
                    result['has_violation'] = True
                    result['violation_type'] = ViolationType.ADULT_IMAGE.value
                    result['severity'] = SeverityLevel.HIGH.value
                    result['details'] = {
                        'reason': 'suspicious_filename',
                        'matched_word': word,
                        'filename': file_name
                    }
                    return result
            
            # ÙØ­Øµ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ÙÙŠØ¯ÙŠÙˆ (Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø·Ø§Ø±Ø§Øª)
            if cv2 and np and video.file_size < 50 * 1024 * 1024:  # Ø£Ù‚Ù„ Ù…Ù† 50 Ù…ÙŠØ¬Ø§
                try:
                    file_info = await message.bot.get_file(video.file_id)
                    if file_info.file_path:
                        file_data = await message.bot.download_file(file_info.file_path)
                        
                        # Ø­ÙØ¸ Ù…Ø¤Ù‚Øª Ù„Ù„ÙÙŠØ¯ÙŠÙˆ
                        temp_video_path = f"/tmp/video_{message.message_id}.mp4"
                        with open(temp_video_path, 'wb') as f:
                            f.write(file_data.read())
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø·Ø§Ø±Ø§Øª Ù„Ù„ÙØ­Øµ
                        frames_analysis = await self._analyze_video_frames(temp_video_path)
                        
                        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                        import os
                        if os.path.exists(temp_video_path):
                            os.remove(temp_video_path)
                        
                        if frames_analysis['has_inappropriate']:
                            result['has_violation'] = True
                            result['violation_type'] = ViolationType.ADULT_IMAGE.value
                            result['severity'] = SeverityLevel.SEVERE.value
                            result['details'] = {
                                'reason': 'video_frame_analysis',
                                'inappropriate_frames': frames_analysis['inappropriate_count'],
                                'total_frames_analyzed': frames_analysis['total_analyzed']
                            }
                            return result
                        
                except Exception as video_analysis_error:
                    logging.debug(f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {video_analysis_error}")
            
            return result
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {e}")
            return result

    async def _check_animation_content(self, message: Message) -> Dict[str, Any]:
        """ÙØ­Øµ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ØªØ­Ø±ÙƒØ© (GIF)"""
        result = {
            'has_violation': False,
            'violation_type': None,
            'severity': 0,
            'details': {},
            'content_summary': f"Ø±Ø³Ù… Ù…ØªØ­Ø±Ùƒ Ù…Ù† {message.from_user.first_name}"
        }
        
        try:
            animation = message.animation
            
            # ÙØ­Øµ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            file_name = getattr(animation, 'file_name', '') or ''
            file_name_lower = file_name.lower()
            
            suspicious_words = [
                'sex', 'porn', 'adult', 'xxx', 'nude',
                'Ø¥Ø¨Ø§Ø­ÙŠ', 'Ø¬Ù†Ø³', 'Ø¹Ø§Ø±ÙŠ'
            ]
            
            for word in suspicious_words:
                if word in file_name_lower:
                    result['has_violation'] = True
                    result['violation_type'] = ViolationType.ADULT_IMAGE.value
                    result['severity'] = SeverityLevel.MEDIUM.value
                    result['details'] = {
                        'reason': 'suspicious_filename',
                        'matched_word': word,
                        'filename': file_name
                    }
                    return result
            
            return result
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ù…ØªØ­Ø±Ùƒ: {e}")
            return result

    async def _check_document_content(self, message: Message) -> Dict[str, Any]:
        """ÙØ­Øµ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„ÙØ§Øª"""
        result = {
            'has_violation': False,
            'violation_type': None,
            'severity': 0,
            'details': {},
            'content_summary': f"Ù…Ù„Ù: {message.document.file_name or 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}"
        }
        
        try:
            document = message.document
            
            # ÙØ­Øµ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
            if document.mime_type and document.mime_type.startswith('image/'):
                # Ù…Ù„Ù ØµÙˆØ±Ø© - ÙØ­Øµ ÙƒØµÙˆØ±Ø©
                file_info = await message.bot.get_file(document.file_id)
                if file_info.file_path:
                    file_data = await message.bot.download_file(file_info.file_path)
                    analysis_result = await self._analyze_image_with_ai(file_data.read())
                    
                    if analysis_result.get('is_inappropriate', False):
                        result['has_violation'] = True
                        result['violation_type'] = ViolationType.ADULT_IMAGE.value
                        result['severity'] = SeverityLevel.HIGH.value
                        result['details'] = {
                            'reason': 'image_document_analysis',
                            'ai_confidence': analysis_result.get('confidence', 0)
                        }
                        return result
            
            # ÙØ­Øµ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            file_name = document.file_name or ''
            file_name_lower = file_name.lower()
            
            suspicious_words = [
                'sex', 'porn', 'adult', 'xxx', 'nude', 'naked',
                'Ø¥Ø¨Ø§Ø­ÙŠ', 'Ø¬Ù†Ø³', 'Ø¹Ø§Ø±ÙŠ', 'Ø¹Ø§Ø±ÙŠØ©'
            ]
            
            for word in suspicious_words:
                if word in file_name_lower:
                    result['has_violation'] = True
                    result['violation_type'] = ViolationType.SUSPICIOUS_FILE.value
                    result['severity'] = SeverityLevel.MEDIUM.value
                    result['details'] = {
                        'reason': 'suspicious_filename',
                        'matched_word': word,
                        'filename': file_name
                    }
                    return result
            
            return result
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù„Ù: {e}")
            return result

    async def _analyze_image_with_ai(self, image_data: bytes) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†"""
        if not Image or not self.model:
            return {
                "is_inappropriate": False,
                "confidence": 0.0,
                "reason": "Ø§Ù„Ù†Ø¸Ø§Ù… ØºÙŠØ± Ù…ØªÙˆÙØ±",
                "category": "error"
            }
        
        try:
            image = Image.open(io.BytesIO(image_data))
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
            max_size = (1024, 1024)
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Ù†Øµ ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø³Ù† ÙˆÙ…ÙØµÙ„
            prompt = """
            Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¯Ù‚Ø© Ø´Ø¯ÙŠØ¯Ø© ÙˆØ­Ø¯Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨.
            
            ÙØ¦Ø§Øª Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨:
            1. Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ù†Ø³ÙŠ Ø§Ù„ØµØ±ÙŠØ­: Ø¹ÙØ±ÙŠ Ø¬Ø²Ø¦ÙŠ Ø£Ùˆ ÙƒØ§Ù…Ù„ØŒ Ù…Ø´Ø§Ù‡Ø¯ Ø¬Ù†Ø³ÙŠØ©ØŒ Ø£ÙˆØ¶Ø§Ø¹ Ø¥ÙŠØ­Ø§Ø¦ÙŠØ©
            2. Ø§Ù„Ø¹Ù†Ù Ø§Ù„Ø´Ø¯ÙŠØ¯: Ø¯Ù…Ø§Ø¡ØŒ Ø¬Ø±ÙˆØ­ØŒ Ø£Ø³Ù„Ø­Ø© Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø¶Ø¯ Ø£Ø´Ø®Ø§Øµ
            3. Ø®Ø·Ø§Ø¨ Ø§Ù„ÙƒØ±Ø§Ù‡ÙŠØ©: Ø±Ù…ÙˆØ² Ø¹Ù†ØµØ±ÙŠØ©ØŒ Ø´Ø¹Ø§Ø±Ø§Øª Ù…ØªØ·Ø±ÙØ©
            4. Ù…Ø­ØªÙˆÙ‰ Ù…Ø®Ø¯Ø±Ø§Øª: ØªØ¹Ø§Ø·ÙŠ ÙˆØ§Ø¶Ø­ Ø£Ùˆ Ø¨ÙŠØ¹ Ù…Ø®Ø¯Ø±Ø§Øª
            
            Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„:
            - Ø§Ù„ÙÙ† Ø§Ù„ØªØ´ÙƒÙŠÙ„ÙŠ ÙˆØ§Ù„Ø±Ø³ÙˆÙ… (Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹ÙØ±ÙŠ ÙÙ†ÙŠ)
            - Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø·Ø¨ÙŠ
            - Ø§Ù„Ø±ÙŠØ§Ø¶Ø© (Ø§Ù„Ø³Ø¨Ø§Ø­Ø©ØŒ ÙƒÙ…Ø§Ù„ Ø§Ù„Ø£Ø¬Ø³Ø§Ù…)
            - Ø§Ù„Ø·Ø¨ÙŠØ¹Ø© ÙˆØ§Ù„Ù…Ù†Ø§Ø¸Ø± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©
            
            Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON Ø¯Ù‚ÙŠÙ‚Ø©:
            {
                "is_inappropriate": true/false,
                "confidence": 0.0-1.0,
                "reason": "Ø³Ø¨Ø¨ Ù…ÙØµÙ„",
                "category": "adult/violence/hate/drugs/safe",
                "specific_elements": ["Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©"]
            }
            """
            
            response = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: self.model.generate_content([prompt, image])
            )
            
            response_text = response.text.strip()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON
            try:
                if '{' in response_text and '}' in response_text:
                    start = response_text.find('{')
                    end = response_text.rfind('}') + 1
                    json_str = response_text[start:end]
                    result = json.loads(json_str)
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    if 'is_inappropriate' in result and 'confidence' in result:
                        return result
                
                # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSONØŒ Ø§Ø³ØªØ®Ø¯Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
                is_inappropriate = any(word in response_text.lower() for word in 
                                    ['inappropriate', 'explicit', 'adult', 'violence', 'inappropriate', 'ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨', 'ØµØ±ÙŠØ­', 'Ø¹Ù†ÙŠÙ'])
                
                return {
                    "is_inappropriate": is_inappropriate,
                    "confidence": 0.7 if is_inappropriate else 0.3,
                    "reason": "ØªØ­Ù„ÙŠÙ„ Ù†ØµÙŠ Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©",
                    "category": "adult" if is_inappropriate else "safe"
                }
                
            except json.JSONDecodeError:
                return {
                    "is_inappropriate": False,
                    "confidence": 0.1,
                    "reason": "Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©",
                    "category": "error"
                }
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return {
                "is_inappropriate": False,
                "confidence": 0.0,
                "reason": f"Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)}",
                "category": "error"
            }

    async def _analyze_video_frames(self, video_path: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
        if not cv2 or not np:
            return {
                'has_inappropriate': False,
                'inappropriate_count': 0,
                'total_analyzed': 0
            }
        
        try:
            cap = cv2.VideoCapture(video_path)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            # ØªØ­Ù„ÙŠÙ„ Ø¥Ø·Ø§Ø± ÙƒÙ„ Ø«Ø§Ù†ÙŠØªÙŠÙ† ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
            step = max(1, int(fps * 2))
            
            inappropriate_count = 0
            total_analyzed = 0
            max_frames_to_analyze = 10  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 10 Ø¥Ø·Ø§Ø±Ø§Øª
            
            for i in range(0, min(frame_count, max_frames_to_analyze * step), step):
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                
                if not ret:
                    break
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø¥Ù„Ù‰ ØµÙˆØ±Ø©
                _, buffer = cv2.imencode('.jpg', frame)
                frame_bytes = buffer.tobytes()
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø±
                analysis = await self._analyze_image_with_ai(frame_bytes)
                
                total_analyzed += 1
                
                if analysis.get('is_inappropriate', False):
                    inappropriate_count += 1
                    
                    # Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ 2 Ø¥Ø·Ø§Ø±Ø§Øª ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨Ø©ØŒ Ù†ØªÙˆÙ‚Ù
                    if inappropriate_count >= 2:
                        break
            
            cap.release()
            
            return {
                'has_inappropriate': inappropriate_count > 0,
                'inappropriate_count': inappropriate_count,
                'total_analyzed': total_analyzed
            }
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {e}")
            return {
                'has_inappropriate': False,
                'inappropriate_count': 0,
                'total_analyzed': 0
            }

    def _determine_punishment_action(self, total_severity: int, user_id: int, chat_id: int) -> PunishmentAction:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø¹Ù‚Ø§Ø¨ÙŠ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø©"""
        try:
            # Ø¬Ù„Ø¨ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
            conn = sqlite3.connect('comprehensive_filter.db')
            cursor = conn.cursor()
            
            # Ø¬Ù„Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ©
            cursor.execute('''
            SELECT total_points, punishment_level, is_permanently_banned 
            FROM user_violation_points 
            WHERE user_id = ? AND chat_id = ?
            ''', (user_id, chat_id))
            
            result = cursor.fetchone()
            
            if result:
                current_points, punishment_level, is_banned = result
                if is_banned:
                    conn.close()
                    return PunishmentAction.BAN_PERMANENT
            else:
                current_points, punishment_level = 0, 0
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (Ù†Ø¶ÙŠÙ 1 Ù„ÙƒÙ„ Ù…Ø®Ø§Ù„ÙØ© Ø¨ØºØ¶ Ø§Ù„Ù†Ø¸Ø± Ø¹Ù† Ø§Ù„Ø´Ø¯Ø© Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø©)
            new_total_points = current_points + 1
            
            # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø© Ø£ÙˆÙ„Ø§Ù‹
            if new_total_points <= 3:
                action = PunishmentAction.WARNING
            else:
                # Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø¯Ø© ÙˆØ§Ù„Ø¹Ø¯Ø¯ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø©
                # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯Ø¯ ÙˆØ§Ù„Ø´Ø¯Ø©
                punishment_level = new_total_points - 3  # Ù†Ø¨Ø¯Ø£ Ù…Ù† 1 Ø¨Ø¹Ø¯ 3 ØªØ­Ø°ÙŠØ±Ø§Øª
                
                # ØªØ¶Ø®ÙŠÙ… Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ø®Ø·ÙˆØ±Ø©
                if total_severity >= 3:  # Ø³Ø¨Ø§Ø¨ Ø´Ø¯ÙŠØ¯
                    punishment_level += 2
                elif total_severity == 2:  # Ø³Ø¨Ø§Ø¨ Ù…ØªÙˆØ³Ø·
                    punishment_level += 1
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
                if punishment_level <= 1:
                    action = PunishmentAction.MUTE_5MIN
                elif punishment_level <= 3:
                    action = PunishmentAction.MUTE_30MIN
                elif punishment_level <= 5:
                    action = PunishmentAction.MUTE_1HOUR
                elif punishment_level <= 8:
                    action = PunishmentAction.MUTE_6HOUR
                elif punishment_level <= 12:
                    action = PunishmentAction.MUTE_24HOUR
                elif punishment_level <= 16:
                    action = PunishmentAction.MUTE_PERMANENT
                else:
                    action = PunishmentAction.BAN_PERMANENT
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù‚Ø§Ø· ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            cursor.execute('''
            INSERT OR REPLACE INTO user_violation_points 
            (user_id, chat_id, total_points, punishment_level, is_permanently_banned)
            VALUES (?, ?, ?, ?, ?)
            ''', (user_id, chat_id, new_total_points, 
                  punishment_level + 1 if 'punishment_level' in locals() else 0, 
                  action == PunishmentAction.BAN_PERMANENT))
            
            conn.commit()
            conn.close()
            
            return action
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø©: {e}")
            return PunishmentAction.WARNING

    async def apply_punishment(self, message: Message, action: PunishmentAction, violations: List[Dict]) -> Dict[str, Any]:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø©"""
        result = {
            'success': False,
            'action_taken': action.value,
            'message_sent': '',
            'admin_notified': False
        }
        
        try:
            # ÙØ­Øµ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª ÙˆØ§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª
            from config.hierarchy import is_master, is_supreme_master
            from modules.supreme_master_commands import get_masters_punishment_status
            
            # Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù…Ø­Ù…ÙŠ Ø¯Ø§Ø¦Ù…Ø§Ù‹
            if is_supreme_master(message.from_user.id):
                result['message_sent'] = "ğŸ‘‘ Ø§Ù„Ø³ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù…Ø­Ù…ÙŠ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª"
                return result
            
            # ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³ÙŠØ§Ø¯ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†
            masters_punishment_enabled = get_masters_punishment_status()
            
            if is_master(message.from_user.id) and not masters_punishment_enabled:
                result['message_sent'] = "ğŸ›¡ï¸ Ø§Ù„Ø£Ø³ÙŠØ§Ø¯ Ù…Ø­Ù…ÙŠÙŠÙ† Ù…Ù† Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª (Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ù…Ø¹Ø·Ù„Ø©)"
                return result
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ù…ÙØ¹Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³ÙŠØ§Ø¯ØŒ Ø³Ø¬Ù„ Ø°Ù„Ùƒ
            if is_master(message.from_user.id) and masters_punishment_enabled:
                logging.warning(f"ğŸ”¥ ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù‚ÙˆØ¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ¯ {message.from_user.id} - Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ù…ÙØ¹Ù„")
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ù„Ù
            try:
                await message.delete()
                logging.info(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ù„Ù Ù…Ù† {message.from_user.id}")
            except Exception as delete_error:
                logging.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø­Ø°Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {delete_error}")
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
            if action == PunishmentAction.WARNING:
                result['message_sent'] = await self._send_warning_message(message, violations)
                result['success'] = True
                
            elif action in [PunishmentAction.MUTE_5MIN, PunishmentAction.MUTE_30MIN, 
                           PunishmentAction.MUTE_1HOUR, PunishmentAction.MUTE_6HOUR, 
                           PunishmentAction.MUTE_24HOUR]:
                mute_success = await self._apply_mute(message, action)
                if mute_success:
                    result['message_sent'] = await self._send_mute_message(message, action, violations)
                    result['success'] = True
                else:
                    result['message_sent'] = "âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙƒØªÙ…"
                    
            elif action == PunishmentAction.MUTE_PERMANENT:
                mute_success = await self._apply_permanent_mute(message)
                if mute_success:
                    result['message_sent'] = await self._send_permanent_mute_message(message, violations)
                    result['success'] = True
                else:
                    result['message_sent'] = "âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙƒØªÙ… Ø§Ù„Ø¯Ø§Ø¦Ù…"
                    
            elif action == PunishmentAction.BAN_PERMANENT:
                ban_success = await self._apply_ban(message)
                if ban_success:
                    result['message_sent'] = await self._send_ban_message(message, violations)
                    result['success'] = True
                else:
                    result['message_sent'] = "âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø·Ø±Ø¯"
            
            # Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ† Ù„Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ø®Ø·ÙŠØ±Ø©
            if any(v['severity'] >= SeverityLevel.HIGH.value for v in violations):
                await self._notify_admins(message, violations, action)
                result['admin_notified'] = True
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ©
            await self._log_violation(message, violations, action)
            
            return result
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø©: {e}")
            result['message_sent'] = f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø©: {str(e)}"
            return result

    async def _apply_mute(self, message: Message, action: PunishmentAction) -> bool:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙƒØªÙ… Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            # ØªØ­Ø¯ÙŠØ¯ Ù…Ø¯Ø© Ø§Ù„ÙƒØªÙ…
            mute_durations = {
                PunishmentAction.MUTE_5MIN: timedelta(minutes=5),
                PunishmentAction.MUTE_30MIN: timedelta(minutes=30),
                PunishmentAction.MUTE_1HOUR: timedelta(hours=1),
                PunishmentAction.MUTE_6HOUR: timedelta(hours=6),
                PunishmentAction.MUTE_24HOUR: timedelta(hours=24)
            }
            
            duration = mute_durations.get(action, timedelta(hours=1))
            mute_until = datetime.now() + duration
            
            permissions = ChatPermissions(
                can_send_messages=False,
                can_send_media_messages=False,
                can_send_polls=False,
                can_send_other_messages=False,
                can_add_web_page_previews=False,
                can_change_info=False,
                can_invite_users=False,
                can_pin_messages=False
            )
            
            await message.bot.restrict_chat_member(
                chat_id=message.chat.id,
                user_id=message.from_user.id,
                permissions=permissions,
                until_date=mute_until
            )
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙƒØªÙ…: {e}")
            return False

    async def _apply_permanent_mute(self, message: Message) -> bool:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙƒØªÙ… Ø§Ù„Ø¯Ø§Ø¦Ù…"""
        try:
            permissions = ChatPermissions(
                can_send_messages=False,
                can_send_media_messages=False,
                can_send_polls=False,
                can_send_other_messages=False,
                can_add_web_page_previews=False,
                can_change_info=False,
                can_invite_users=False,
                can_pin_messages=False
            )
            
            await message.bot.restrict_chat_member(
                chat_id=message.chat.id,
                user_id=message.from_user.id,
                permissions=permissions
            )
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙƒØªÙ… Ø§Ù„Ø¯Ø§Ø¦Ù…: {e}")
            return False

    async def _apply_ban(self, message: Message) -> bool:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø·Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        try:
            await message.bot.ban_chat_member(
                chat_id=message.chat.id,
                user_id=message.from_user.id
            )
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø·Ø±Ø¯: {e}")
            return False

    async def _send_warning_message(self, message: Message, violations: List[Dict]) -> str:
        """Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ØªØ­Ø°ÙŠØ±"""
        violation_types = [v['violation_type'] for v in violations]
        
        warning_msg = f"âš ï¸ **ØªØ­Ø°ÙŠØ± Ù„Ù€ {message.from_user.first_name}**\n\n"
        warning_msg += f"ğŸš¨ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨:\n"
        
        for violation in violations:
            warning_msg += f"â€¢ {self._get_violation_description(violation['violation_type'])}\n"
        
        warning_msg += f"\nğŸ›¡ï¸ **Ù‡Ø°Ø§ ØªØ­Ø°ÙŠØ± Ø±Ø³Ù…ÙŠ - Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ø³ØªØ¤Ø¯ÙŠ Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø£Ù‚ÙˆÙ‰**"
        
        await message.answer(warning_msg)
        return warning_msg

    async def _send_mute_message(self, message: Message, action: PunishmentAction, violations: List[Dict]) -> str:
        """Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ÙƒØªÙ…"""
        duration_names = {
            PunishmentAction.MUTE_5MIN: "5 Ø¯Ù‚Ø§Ø¦Ù‚",
            PunishmentAction.MUTE_30MIN: "30 Ø¯Ù‚ÙŠÙ‚Ø©",
            PunishmentAction.MUTE_1HOUR: "Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©",
            PunishmentAction.MUTE_6HOUR: "6 Ø³Ø§Ø¹Ø§Øª",
            PunishmentAction.MUTE_24HOUR: "24 Ø³Ø§Ø¹Ø©"
        }
        
        duration = duration_names.get(action, "Ù…Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø©")
        
        mute_msg = f"ğŸ”‡ **ØªÙ… ÙƒØªÙ… {message.from_user.first_name}**\n\n"
        mute_msg += f"â° **Ù…Ø¯Ø© Ø§Ù„ÙƒØªÙ…:** {duration}\n"
        mute_msg += f"ğŸš¨ **Ø§Ù„Ø³Ø¨Ø¨:** Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨\n\n"
        
        for violation in violations:
            mute_msg += f"â€¢ {self._get_violation_description(violation['violation_type'])}\n"
        
        mute_msg += f"\nğŸ›¡ï¸ **Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„ ÙØ¹Ø§Ù„ - Ø§Ø­ØªØ±Ù…ÙˆØ§ Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©**"
        
        await message.answer(mute_msg)
        return mute_msg

    async def _send_permanent_mute_message(self, message: Message, violations: List[Dict]) -> str:
        """Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ÙƒØªÙ… Ø§Ù„Ø¯Ø§Ø¦Ù…"""
        mute_msg = f"ğŸ”‡ **ØªÙ… ÙƒØªÙ… {message.from_user.first_name} Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹**\n\n"
        mute_msg += f"âš ï¸ **Ø§Ù„Ø³Ø¨Ø¨:** Ù…Ø®Ø§Ù„ÙØ§Øª Ù…ØªÙƒØ±Ø±Ø© Ù„Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†\n"
        mute_msg += f"ğŸš¨ **Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø©:**\n"
        
        for violation in violations:
            mute_msg += f"â€¢ {self._get_violation_description(violation['violation_type'])}\n"
        
        mute_msg += f"\nğŸ›¡ï¸ **Ø§Ù„ÙƒØªÙ… Ø§Ù„Ø¯Ø§Ø¦Ù… - Ù„Ù† ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰**"
        mute_msg += f"\nğŸ“ **Ù„Ù„Ø§Ø³ØªØ¦Ù†Ø§Ù:** Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©"
        
        await message.answer(mute_msg)
        return mute_msg

    async def _send_ban_message(self, message: Message, violations: List[Dict]) -> str:
        """Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø·Ø±Ø¯"""
        ban_msg = f"ğŸš« **ØªÙ… Ø·Ø±Ø¯ {message.from_user.first_name} Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹**\n\n"
        ban_msg += f"âš ï¸ **Ø§Ù„Ø³Ø¨Ø¨:** Ù…Ø®Ø§Ù„ÙØ§Øª Ø®Ø·ÙŠØ±Ø© ÙˆÙ…ØªÙƒØ±Ø±Ø©\n"
        ban_msg += f"ğŸš¨ **Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø©:**\n"
        
        for violation in violations:
            ban_msg += f"â€¢ {self._get_violation_description(violation['violation_type'])}\n"
        
        ban_msg += f"\nğŸš« **ØªÙ… Ù…Ù†Ø¹Ù‡ Ù…Ù† Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©**"
        ban_msg += f"\nğŸ›¡ï¸ **Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„ - ØµÙØ± ØªØ³Ø§Ù…Ø­ Ù…Ø¹ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ø®Ø·ÙŠØ±Ø©**"
        
        await message.answer(ban_msg)
        return ban_msg

    def _get_violation_description(self, violation_type: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙˆØµÙ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ©"""
        descriptions = {
            ViolationType.TEXT_PROFANITY.value: "Ø£Ù„ÙØ§Ø¸ Ù…Ø³ÙŠØ¦Ø© ÙˆØ³Ø¨Ø§Ø¨",
            ViolationType.SEXUAL_CONTENT.value: "Ù…Ø­ØªÙˆÙ‰ Ø¬Ù†Ø³ÙŠ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨",
            ViolationType.ADULT_IMAGE.value: "ØµÙˆØ± Ø¥Ø¨Ø§Ø­ÙŠØ© Ø£Ùˆ ÙØ§Ø¶Ø­Ø©",
            ViolationType.VIOLENT_CONTENT.value: "Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†ÙŠÙ",
            ViolationType.HATE_SPEECH.value: "Ø®Ø·Ø§Ø¨ ÙƒØ±Ø§Ù‡ÙŠØ©",
            ViolationType.INAPPROPRIATE_STICKER.value: "Ù…Ù„ØµÙ‚ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨",
            ViolationType.SUSPICIOUS_FILE.value: "Ù…Ù„Ù Ù…Ø´Ø¨ÙˆÙ‡"
        }
        
        return descriptions.get(violation_type, "Ù…Ø®Ø§Ù„ÙØ© ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©")

    async def _notify_admins(self, message: Message, violations: List[Dict], action: PunishmentAction):
        """Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ† Ø¨Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ø®Ø·ÙŠØ±Ø©"""
        try:
            # Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ†
            chat_administrators = await message.bot.get_chat_administrators(message.chat.id)
            
            notification_msg = f"ğŸš¨ **ØªÙ‚Ø±ÙŠØ± Ù…Ø®Ø§Ù„ÙØ© Ø®Ø·ÙŠØ±Ø©**\n\n"
            notification_msg += f"ğŸ‘¤ **Ø§Ù„Ù…Ø®Ø§Ù„Ù:** {message.from_user.first_name} (@{message.from_user.username or 'Ù„Ø§ ÙŠÙˆØ¬Ø¯'})\n"
            notification_msg += f"ğŸ  **Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©:** {message.chat.title}\n"
            notification_msg += f"â° **Ø§Ù„ÙˆÙ‚Øª:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
            
            notification_msg += f"ğŸš¨ **Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª:**\n"
            for violation in violations:
                notification_msg += f"â€¢ {self._get_violation_description(violation['violation_type'])}\n"
                if 'details' in violation and violation['details']:
                    details = violation['details']
                    if 'ai_confidence' in details:
                        notification_msg += f"  Ø§Ù„Ø«Ù‚Ø©: {details['ai_confidence']:.2f}\n"
            
            notification_msg += f"\nâš–ï¸ **Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…ØªØ®Ø°:** {self._get_action_description(action)}\n"
            notification_msg += f"ğŸ”— **Ø±Ø§Ø¨Ø· Ø§Ù„Ø±Ø³Ø§Ù„Ø©:** [Ø§Ù†Ù‚Ø± Ù‡Ù†Ø§](https://t.me/c/{str(message.chat.id)[4:]}/{message.message_id})"
            
            # Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù…Ø´Ø±ÙÙŠÙ† ÙÙŠ Ø§Ù„Ø®Ø§Øµ
            for admin in chat_administrators:
                if admin.user.is_bot:
                    continue
                
                try:
                    await message.bot.send_message(
                        admin.user.id,
                        notification_msg,
                        parse_mode='Markdown'
                    )
                except Exception as send_error:
                    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø¥Ø±Ø³Ø§Ù„ ÙÙŠ Ø§Ù„Ø®Ø§ØµØŒ ØªØ¬Ø§Ù‡Ù„
                    logging.debug(f"Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±Ù {admin.user.id}: {send_error}")
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            await self._save_admin_report(message, violations, action)
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙÙŠÙ†: {e}")

    def _get_action_description(self, action: PunishmentAction) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙˆØµÙ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡"""
        descriptions = {
            PunishmentAction.WARNING: "ØªØ­Ø°ÙŠØ±",
            PunishmentAction.MUTE_5MIN: "ÙƒØªÙ… 5 Ø¯Ù‚Ø§Ø¦Ù‚",
            PunishmentAction.MUTE_30MIN: "ÙƒØªÙ… 30 Ø¯Ù‚ÙŠÙ‚Ø©",
            PunishmentAction.MUTE_1HOUR: "ÙƒØªÙ… Ø³Ø§Ø¹Ø©",
            PunishmentAction.MUTE_6HOUR: "ÙƒØªÙ… 6 Ø³Ø§Ø¹Ø§Øª",
            PunishmentAction.MUTE_24HOUR: "ÙƒØªÙ… 24 Ø³Ø§Ø¹Ø©",
            PunishmentAction.MUTE_PERMANENT: "ÙƒØªÙ… Ø¯Ø§Ø¦Ù…",
            PunishmentAction.BAN_PERMANENT: "Ø·Ø±Ø¯ Ù†Ù‡Ø§Ø¦ÙŠ"
        }
        
        return descriptions.get(action, "Ø¥Ø¬Ø±Ø§Ø¡ ØºÙŠØ± Ù…Ø­Ø¯Ø¯")

    async def _save_admin_report(self, message: Message, violations: List[Dict], action: PunishmentAction):
        """Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ù„Ù„Ù…Ø´Ø±ÙÙŠÙ†"""
        try:
            conn = sqlite3.connect('comprehensive_filter.db')
            cursor = conn.cursor()
            
            for violation in violations:
                cursor.execute('''
                INSERT INTO admin_reports 
                (chat_id, user_id, violation_type, severity_level, content_summary, action_taken)
                VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    message.chat.id,
                    message.from_user.id,
                    violation['violation_type'],
                    violation['severity'],
                    violation.get('content_summary', ''),
                    action.value
                ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")

    async def _log_violation(self, message: Message, violations: List[Dict], action: PunishmentAction):
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ© ÙÙŠ Ø§Ù„Ø³Ø¬Ù„"""
        try:
            conn = sqlite3.connect('comprehensive_filter.db')
            cursor = conn.cursor()
            
            for violation in violations:
                expiry_date = None
                if action in [PunishmentAction.MUTE_5MIN, PunishmentAction.MUTE_30MIN, 
                             PunishmentAction.MUTE_1HOUR, PunishmentAction.MUTE_6HOUR, 
                             PunishmentAction.MUTE_24HOUR]:
                    durations = {
                        PunishmentAction.MUTE_5MIN: timedelta(minutes=5),
                        PunishmentAction.MUTE_30MIN: timedelta(minutes=30),
                        PunishmentAction.MUTE_1HOUR: timedelta(hours=1),
                        PunishmentAction.MUTE_6HOUR: timedelta(hours=6),
                        PunishmentAction.MUTE_24HOUR: timedelta(hours=24)
                    }
                    expiry_date = datetime.now() + durations.get(action, timedelta(hours=1))
                
                cursor.execute('''
                INSERT INTO violation_history 
                (user_id, chat_id, violation_type, severity_level, content_summary, punishment_applied, expires_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    message.from_user.id,
                    message.chat.id,
                    violation['violation_type'],
                    violation['severity'],
                    violation.get('content_summary', ''),
                    action.value,
                    expiry_date
                ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ©: {e}")

    async def get_user_violations_summary(self, user_id: int, chat_id: int) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        try:
            conn = sqlite3.connect('comprehensive_filter.db')
            cursor = conn.cursor()
            
            # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª
            cursor.execute('''
            SELECT COUNT(*), SUM(severity_level) 
            FROM violation_history 
            WHERE user_id = ? AND chat_id = ?
            ''', (user_id, chat_id))
            
            total_violations, total_severity = cursor.fetchone()
            total_violations = total_violations or 0
            total_severity = total_severity or 0
            
            # Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            cursor.execute('''
            SELECT total_points, punishment_level, is_permanently_banned 
            FROM user_violation_points 
            WHERE user_id = ? AND chat_id = ?
            ''', (user_id, chat_id))
            
            points_result = cursor.fetchone()
            if points_result:
                current_points, punishment_level, is_banned = points_result
            else:
                current_points, punishment_level, is_banned = 0, 0, False
            
            # Ø¢Ø®Ø± Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª
            cursor.execute('''
            SELECT violation_type, severity_level, created_at 
            FROM violation_history 
            WHERE user_id = ? AND chat_id = ? 
            ORDER BY created_at DESC 
            LIMIT 5
            ''', (user_id, chat_id))
            
            recent_violations = cursor.fetchall()
            
            conn.close()
            
            return {
                'total_violations': total_violations,
                'total_severity': total_severity,
                'current_points': current_points,
                'punishment_level': punishment_level,
                'is_permanently_banned': is_banned,
                'recent_violations': [
                    {
                        'type': v[0],
                        'severity': v[1],
                        'date': v[2]
                    } for v in recent_violations
                ]
            }
            
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø®Ø§Ù„ÙØ§Øª: {e}")
            return {
                'total_violations': 0,
                'total_severity': 0,
                'current_points': 0,
                'punishment_level': 0,
                'is_permanently_banned': False,
                'recent_violations': []
            }

    async def _check_text_with_ai(self, text: str) -> Dict[str, Any]:
        """ÙØ­Øµ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Gemini"""
        try:
            if not self.model:
                return {'has_profanity': False}
            
            prompt = f"""
Ø£Ù†Øª Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„ÙƒØ´Ù Ø§Ù„Ø³Ø¨Ø§Ø¨ ÙˆØ§Ù„Ø£Ù„ÙØ§Ø¸ Ø§Ù„Ù…Ø³ÙŠØ¦Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ­Ø¯Ø¯:
1. Ù‡Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø³Ø¨Ø§Ø¨ Ø£Ùˆ Ø£Ù„ÙØ§Ø¸ Ù…Ø³ÙŠØ¦Ø©ØŸ
2. Ù…Ø§ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø© Ù…Ù† 1-5ØŸ
3. Ù…Ø§ Ø§Ù„Ø³Ø¨Ø¨ØŸ

Ø§Ù„Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„: "{text}"

Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ù€ JSON:
{{"has_profanity": true/false, "severity": 1-5, "reason": "Ø§Ù„Ø³Ø¨Ø¨", "confidence": 0.0-1.0}}
"""
            
            response = await asyncio.to_thread(
                self.model.generate_content, 
                prompt
            )
            
            import json
            try:
                result = json.loads(response.text.strip())
                return result
            except:
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø©
                response_text = response.text.lower()
                if any(word in response_text for word in ['true', 'profanity', 'Ø³Ø¨Ø§Ø¨', 'Ù…Ø³ÙŠØ¡']):
                    return {'has_profanity': True, 'severity': 3, 'reason': 'ÙƒÙØ´Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ', 'confidence': 0.8}
                else:
                    return {'has_profanity': False, 'severity': 0, 'reason': 'Ù†Øµ Ù†Ø¸ÙŠÙ', 'confidence': 0.9}
                    
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {e}")
            return {'has_profanity': False}

# Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ø¬ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„
comprehensive_filter = ComprehensiveContentFilter()